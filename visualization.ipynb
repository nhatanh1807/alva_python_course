{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\ADMIN\\Downloads\\laptop_da\\cleaned_asin_added.csv')\n",
    "df_laptop = df.loc[df['type'] == 'laptop']\n",
    "df_laptop\n",
    "df_laptop.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = df_laptop.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "corr_matrix = df_laptop[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "high_corr_vars = corr_matrix[(corr_matrix.abs() > threshold) & (corr_matrix.abs() < 1)]\n",
    "print(high_corr_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_laptop[numeric_cols] = scaler.fit_transform(df_laptop[numeric_cols])\n",
    "\n",
    "corr_matrix = df_laptop[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_laptop.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['lmsales_converted', 'reviews', 'rating', 'wait_days', 'ram', 'storage_capacity']\n",
    "target = 'price'\n",
    "\n",
    "X = df_laptop[features]\n",
    "y = df_laptop[target]\n",
    "\n",
    "numeric_features = ['lmsales_converted', 'reviews', 'rating', 'wait_days', 'ram', 'storage_capacity']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)\n",
    "    ])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'MAE: {mae}')\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'R2 Score: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = {\n",
    "    'lmsales_converted': [200, 150],\n",
    "    'reviews': [50, 30],\n",
    "    'rating': [4.5, 4.0],\n",
    "    'wait_days': [7, 10],\n",
    "    'ram': [16, 8],\n",
    "    'storage_capacity': [512, 256]\n",
    "}\n",
    "\n",
    "df_new_data = pd.DataFrame(new_data)\n",
    "\n",
    "y_real_pred = model.predict(df_new_data)\n",
    "\n",
    "df_new_data['predicted_price'] = y_real_pred\n",
    "\n",
    "print(df_new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['lmsales_converted', 'reviews', 'rating', 'wait_days', 'ram', 'storage_capacity']\n",
    "target = 'price'\n",
    "\n",
    "X = df_laptop[features]\n",
    "y = df_laptop[target]\n",
    "\n",
    "numeric_features = ['lmsales_converted', 'reviews', 'rating', 'wait_days', 'ram', 'storage_capacity']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)\n",
    "    ])\n",
    "\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestRegressor(),\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"DecisionTree\": DecisionTreeRegressor()\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', model)\n",
    "    ])\n",
    "    \n",
    "    cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='r2')\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Cross-Validation R2 Scores: {cv_scores}\")\n",
    "    print(f\"Mean CV R2 Score: {cv_scores.mean()}\")\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"MAE: {mae}\")\n",
    "    print(f\"MSE: {mse}\")\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print(f\"R2 Score: {r2}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [100, 200, 300],\n",
    "    'regressor__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'regressor__max_depth': [10, 20, 30, None]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "]), param_grid=param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation R2 score: {grid_search.best_score_}\")\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Final Model MAE: {mae}\")\n",
    "print(f\"Final Model MSE: {mse}\")\n",
    "print(f\"Final Model RMSE: {rmse}\")\n",
    "print(f\"Final Model R2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"RandomForest\": RandomForestRegressor(),\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"DecisionTree\": DecisionTreeRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = {\n",
    "    'lmsales_converted': [200, 150],\n",
    "    'reviews': [50, 30],\n",
    "    'rating': [4.5, 4.0],\n",
    "    'wait_days': [7, 10],\n",
    "    'ram': [16, 8],\n",
    "    'storage_capacity': [512, 256]\n",
    "}\n",
    "\n",
    "df_new_data = pd.DataFrame(new_data)\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Testing Model: {model_name}\")\n",
    "    \n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', model)\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"MAE: {mae}\")\n",
    "    print(f\"MSE: {mse}\")\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print(f\"R2 Score: {r2}\")\n",
    "    \n",
    "    y_real_pred = pipeline.predict(df_new_data)\n",
    "    \n",
    "    df_new_data[f'predicted_price_{model_name}'] = y_real_pred\n",
    "    \n",
    "    print(df_new_data)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_lmsales_reviews = df_laptop[['lmsales_converted', 'reviews']].corr().iloc[0, 1]\n",
    "print(f\"Hệ số tương quan giữa 'lmsales_converted' và 'reviews': {corr_lmsales_reviews}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='lmsales_converted', y='reviews', data=df_laptop)\n",
    "plt.title('Biểu đồ phân tán giữa lmsales_converted và reviews')\n",
    "plt.xlabel('lmsales_converted')\n",
    "plt.ylabel('reviews')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_price_by_brand = df_laptop.groupby('brand')['price'].mean().reset_index()\n",
    "avg_price_by_brand.columns = ['brand', 'avg_price']\n",
    "\n",
    "print(avg_price_by_brand)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='brand', y='avg_price', data=avg_price_by_brand, palette='viridis')\n",
    "plt.title('Giá tiền trung bình theo thương hiệu')\n",
    "plt.xlabel('Thương hiệu')\n",
    "plt.ylabel('Giá tiền trung bình')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_price_by_brand_cpu = df_laptop.groupby(['brand', 'cpu_brand'])['price'].mean().reset_index()\n",
    "avg_price_by_brand_cpu.columns = ['brand', 'cpu_brand', 'avg_price']\n",
    "\n",
    "print(avg_price_by_brand_cpu)\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.barplot(x='avg_price', y='brand', hue='cpu_brand', data=avg_price_by_brand_cpu, palette='viridis')\n",
    "plt.title('Giá tiền trung bình theo thương hiệu và loại CPU')\n",
    "plt.xlabel('Giá tiền trung bình')\n",
    "plt.ylabel('Thương hiệu')\n",
    "plt.legend(title='CPU Brand')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_counts = df_laptop['brand'].value_counts()\n",
    "print(brand_counts)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "brand_counts.plot(kind='bar')\n",
    "plt.title('Số lượng laptop theo nhãn hiệu')\n",
    "plt.xlabel('Nhãn hiệu')\n",
    "plt.ylabel('Số lượng')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_counts = df_laptop['cpu_brand'].value_counts()\n",
    "cpu_counts\n",
    "plt.figure(figsize=(10, 6))\n",
    "cpu_counts.plot(kind='bar')\n",
    "plt.title('Số lượng laptop theo nhãn hiệu CPU')\n",
    "plt.xlabel('Nhãn hiệu CPU')\n",
    "plt.ylabel('Số lượng')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ram_counts = df_laptop['ram'].value_counts()\n",
    "ram_counts\n",
    "plt.figure(figsize=(10, 6))\n",
    "ram_counts.plot(kind='bar')\n",
    "plt.title('Số lượng laptop theo nhãn hiệu')\n",
    "plt.xlabel('Dung lượng RAM')\n",
    "plt.ylabel('Số lượng')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity_counts = df_laptop['storage_capacity'].value_counts()\n",
    "capacity_counts\n",
    "plt.figure(figsize=(10, 6))\n",
    "capacity_counts.plot(kind='bar')\n",
    "plt.title('Số lượng laptop theo dung lượng bộ nhớ')\n",
    "plt.xlabel('Dung lượng')\n",
    "plt.ylabel('Số lượng')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity_counts = df_laptop['storage_type'].value_counts()\n",
    "capacity_counts\n",
    "plt.figure(figsize=(10, 6))\n",
    "capacity_counts.plot(kind='bar')\n",
    "plt.title('Số lượng laptop theo kiểu bộ nhớ')\n",
    "plt.xlabel('Loại')\n",
    "plt.ylabel('Số lượng')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_laptop['rating'] = pd.to_numeric(df_laptop['rating'], errors='coerce')\n",
    "df_laptop['lmsales_converted'] = pd.to_numeric(df_laptop['lmsales_converted'], errors='coerce')\n",
    "df_laptop['reviews'] = pd.to_numeric(df_laptop['reviews'], errors='coerce')\n",
    "\n",
    "print(df_laptop.dtypes)\n",
    "\n",
    "grouped_df = df_laptop.groupby('brand')[['rating', 'lmsales_converted', 'reviews']].mean()\n",
    "\n",
    "print(grouped_df.head())\n",
    "\n",
    "brands = grouped_df.index\n",
    "avg_values = grouped_df.values.T\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "bar_width = 0.2\n",
    "index = np.arange(len(brands))\n",
    "\n",
    "for i, (metric, color) in enumerate(zip(['rating', 'lmsales_converted', 'reviews'], ['blue', 'green', 'red'])):\n",
    "    plt.bar(index + i * bar_width, avg_values[i], bar_width, label=metric, color=color)\n",
    "\n",
    "plt.title('Trung bình các chỉ số theo Brand')\n",
    "plt.xlabel('Brand')\n",
    "plt.ylabel('Giá trị trung bình')\n",
    "plt.xticks(index + bar_width * 1.5, brands, rotation=45)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
