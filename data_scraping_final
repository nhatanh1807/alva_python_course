import time
import os
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager

chromedriver_path = 'C:\\Users\\ADMIN\\Downloads\\chromedriver-win64\\chromedriver.exe'
service = Service(executable_path=chromedriver_path)
chrome_options = webdriver.ChromeOptions()
wd = webdriver.Chrome(service=service, options=chrome_options)

def add_data(names, prices, links, delivery_dates, last_month_boughts, ratings, rate_turns, num_lefts, ships):
    elements = wd.find_elements(By.CSS_SELECTOR, ".s-main-slot .s-result-item")
    for element in elements:
        try:
            name = element.find_element(By.CSS_SELECTOR, "h2 a span").text
            price = element.find_element(By.CSS_SELECTOR, ".a-price-whole").text
            link = element.find_element(By.CSS_SELECTOR, "h2 a").get_attribute("href")
            delivery_date_elements = element.find_elements(By.CSS_SELECTOR, '[aria-label^="Delivery"]')
            delivery_date = delivery_date_elements[0].get_attribute("aria-label") if delivery_date_elements else "N/A"
        
            last_month_bought_elements = element.find_elements(By.CSS_SELECTOR, ".a-size-base.a-color-secondary")
            last_month_bought = last_month_bought_elements[0].text if last_month_bought_elements else "N/A"
            # Extract rating
            rating_elements = element.find_elements(By.CSS_SELECTOR, '[aria-label*="out of 5 stars"]')
            rating = rating_elements[0].get_attribute("aria-label") if rating_elements else "N/A"
           
            review_elements = element.find_elements(By.CSS_SELECTOR, ".a-size-base.s-underline-text")
            rate_turn = review_elements[0].text if review_elements else "N/A"
           
            num_left_elements = element.find_elements(By.CSS_SELECTOR, ".a-truncate-full.a-offscreen")
            num_left = num_left_elements[0].text if num_left_elements else "N/A"
         
            ship_elements = element.find_elements(By.CSS_SELECTOR, ".a-size-small.a-color-base")
            ship = ship_elements[0].text if ship_elements else "N/A"
            names.append(name)
            prices.append(price)
            links.append(link)
            delivery_dates.append(delivery_date)
            last_month_boughts.append(last_month_bought)
            ratings.append(rating)
            rate_turns.append(rate_turn)
            num_lefts.append(num_left)
            ships.append(ship)
        except Exception as e:
            print(f"Error occurred while extracting data: {e}")
    return names, prices, links, delivery_dates, last_month_boughts, ratings, rate_turns, num_lefts, ships

try:
    url = "https://www.amazon.vn/"
    wd.get(url)

    element = WebDriverWait(wd, 10).until(
        EC.presence_of_element_located((By.ID, "twotabsearchtextbox"))
    )

    element.send_keys("Laptop")
    element.send_keys(Keys.ENTER)

    WebDriverWait(wd, 10).until(
        EC.presence_of_element_located((By.CSS_SELECTOR, ".s-main-slot .s-result-item"))
    )

    names, prices, links, delivery_dates, last_month_boughts, ratings, rate_turns, num_lefts, ships = [], [], [], [], [], [], [], [], []

    max_pages = 500
    current_page = 1

    while current_page <= max_pages:
        try:
            names, prices, links, delivery_dates, last_month_boughts, ratings, rate_turns, num_lefts, ships = add_data(names, prices, links, delivery_dates, last_month_boughts, ratings, rate_turns, num_lefts, ships)

            next_button = WebDriverWait(wd, 10).until(
                EC.element_to_be_clickable((By.CSS_SELECTOR, ".s-pagination-next"))
            )
            next_button.click()
            time.sleep(2)
            WebDriverWait(wd, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, ".s-main-slot .s-result-item"))
            )

            current_page += 1
        except Exception as e:
            print(f"No more pages or error occurred: {e}")
            break

    df = pd.DataFrame({
        'Name': names,
        'Price': prices,
        'Link': links,
        'ngay_giao_hang' : delivery_dates,
        'luot_mua_thang_truoc' : last_month_boughts,
        'diem_danh_gia' : ratings,
        'luot_danh_gia' : rate_turns,
        'so_option_khac' : num_lefts,
        'ship' : ships
    })

    print(df)

    if df.empty:
        print("No data was scraped.")
    else:
        script_dir = os.path.dirname(os.path.abspath(__file__)) if '__file__' in globals() else os.getcwd()
        file_path = os.path.join(script_dir, 'ama_laptop.csv')
        print(f"Saving CSV to: {file_path}")
        df.to_csv(file_path, index=False)
        print("CSV file saved successfully.")

finally:
    wd.quit()
